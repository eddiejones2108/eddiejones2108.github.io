<!DOCTYPE html>
<html lang="en-UK">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <meta name="author" content="Eddie Jones">
  <meta name="description" content="Some random thoughts on computer science and philosophy">

  <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" type="text/css" href="style.css">
  <title>Assorted Musings</title>
</head>

<body>
  <header>
    <h2>Eddie Jones
      <a href="mailto: ej16147@bristol.ac.uk" class="fa fa-envelope"></a>
      <a href="https://github.com/eddiejones2108" class="fa fa-github"></a>
      <a href="https://www.linkedin.com/in/edward-jones-b59a80151/" class="fa fa-linkedin"></a>
    </h2>

    <h1><a href="index.html#">Assorted Musings</a></h1>
  </header>

  <main>
    <section>
      <h3>How Cancer Sneaks up on a Reductionist</h3>
      <p>
        I wrote this essay as an entry for the Kurt GÃ¶del Award 2019, which intends to inspire anti-reductionist
        knowledge. Instead of focusing on the epistemology perspective, I chose a more practical bent.
        Although I didn't win the award, I really enjoyed writing the essay, and I hope you might enjoy reading it!
      </p>
      <p>
        Please excuse the clickbait title.
      </p>
    </section>

    <section>
      <p>
        Reductionism refers to a methodological and ontological theory, both of which attempt to connect phenomena with
        other lower-level phenomena. Though these two concepts are distinct, they are interdependent and often
        conflated. For example, the behaviour of a system that doesn't consist of several autonomous entities can't be
        explained in terms of them. In the 20th century, physicists discovered and verified quantum entanglement, which
        had significant implications for ontological reductionists. However, obscure interpretations of quantum
        mechanics can eschew this issue. So if ontological reductionism doesn't contradict modern physics, can it also
        form the basis of a sound methodology? Through the colloquial phrase <em>How long is a piece of string?</em>
        this essay will explore where natural complexity is unyielding to methodological reductionism and consider why
        such a question is important.
      </p>
    </section>

    <section>
      <p>
        The precursor to reductionism was atomism. As the name suggests, this theory asserts that all matter comprises a
        multitude of indivisible parts, or <em>atoms</em>, that give rise to macroscopic properties. Despite being
        abandoned in
        the Middle Ages, this theory reemerged with the Scientific Revolution and the millennium-long pursuit of these
        particles continued. As the scale became smaller <em>spooky</em> results emerged &mdash; quantum mechanics.
        Einstein
        was famously sceptical of quantum mechanics, especially regarding his belief in local realism. The principle of
        local realism asserts that the universe is objective, i.e. values exist before measurement and that the speed of
        light limits all interactions. Although an intuitive and familiar principle to the world of classical mechanics,
        it was eventually disproved by Bell's experiment in 1972. Under most traditional interpretations of quantum
        mechanics, such as the Copenhagen interpretation, reality appeared to be non-local.
      </p>
    </section>

    <section>
      <p>
        The non-locality of cause and effect alludes to a necessary rejection of reductionism on metaphysical grounds;
        if the particles don't dictate their own behaviour, it is ingenuous to study, or indeed view, them
        independently. However, there are interpretations of quantum mechanics that circumnavigate these issues, namely
        relational quantum mechanics. By viewing the state as the relationship between the observer and the system,
        relational quantum mechanics describes a local theory consistent with Bell's experiment. The first proponent of
        this interpretation, Carlo Rovelli, took an <em>instrumentalist</em> view of his model:
      </p>

      <blockquote>
        Quantum mechanics is a theory about the physical description of physical systems relative to other systems, and
        this is a complete description of the world.
      </blockquote>
    </section>

    <section>
      <p>
        Typically several models can describe a system, each from different perspectives, and in most cases one will
        be reductionist. However, each model's tractability will vary considerably, rendering the application of some
        like trying to square a circle. Rovelli thought of his theory as a model, not as a description of objective
        reality. In this sense, he is still an anti-realist.
      </p>
    </section>

    <section>
      <p>
        An area where reductionism, almost by definition, cannot be of assistance is the study of fractals. The
        assumption that there is more tractable information at a smaller scale forms the heart of reductionism, and
        consequently much of pre-modern mathematics. For example, calculus relies on the <em>smoothness</em>, and
        <em>simplicity</em>, of the infinitesimal, and likewise, geometry composes the anachronistic <em>perfect</em>
        forms inherited from ancient Greece. Benoit Mandelbrot, the father of fractal geometry, realised the critical
        difference between this undetailed style mathematics and nature, writing:
      </p>

      <blockquote>
        Clouds are not spheres, mountains are not cones, coastlines are not circles, and bark is not smooth, nor does
        lightning travel in a straight line.
      </blockquote>
    </section>

    <section>
      <p>
        The inherent roughness of these objects extends right to their core, and so to no practical extent can
        reductionism be of assistance. This argument and the remarkable futility of the reductionist analysis of
        fractals is illustrated well by mathematical archetypes such as the Mandelbrot Set. These shapes are perfectly
        self- similar, i.e. they are composed of exact copies of themselves and so upon decomposition only more fractals
        are found &mdash; hardly a benefficial analysis. A speciffic instance of this circular issue is the Coastline
        Paradox where the length of ordinary objects, such as a piece of string, becomes undefined because of their
        roughness. Of course, these shapes differ from the mathematical forms in that their self-similarity isn't
        necessarily infinitely nor regularly recursive (merely statistically self-similar). However, at the atomic
        scale, or indeed subatomic, position itself becomes uncertain, and so the argument still stands. A common
        frustrated response to a question about an undefined (or unknown) quantity, such as length, is <em>How long is a
          piece of string?</em>. This idiomatic expression, I believe, captures the intractability of fractal complexity
        and
        the measurement paradox. As ultimately, reductionism cannot determine its length.
      </p>
    </section>

    <section>
      <p>
        On the other hand, the dimension of length has proved sufficiently robust a foundation on which physics
        can rest; it appears, as with the interpretations/models of quantum mechanics, both views have something to
        add. It is only within the last hundred years that fractals have gained recognition as more than
        <em>pathological</em> oddities, and so fractal analysis is yet to prove itself. However, it already has lent
        itself to a broad range of applications from neuroscience to urban geography. The essential tool used in this
        method of analysis is the fractal dimension which quantifies the roughness, or complexity, of an entity by
        comparing its level of detail at different scales. As with any measurement, this only provides a shadow of
        all the potential information. However, as the complexity of a perimeter and its length are closely correlated,
        they contain some of the same information. Additionally, it is not hard to imagine a situation where the fractal
        dimension is more readily available (or at least well-defined) due to it being a measurement that is more
        intrinsic to the system. Fractal dimension can provide a scale-free alternative for length (or volume, et
        cetera) in some contexts.
      </p>
    </section>

    <section>
      <p>
        An example where this substitution has a tangible impact is cancer diagnostics. Oncologists typically
        use the volume of a tumour to assess its stage of development. However, this method has a missing link;
        the size of the tissue changes little for a period, then rapidly expands for no clear reason. It is in this
        latter stage that the tumour becomes malignant, but it is critical to identify it before this point. The
        non-linearity of the expansion in volume indicates that it is a consequence of a more fundamental process.
        Researchers have recently turned to fractal dimension for assessing the normality of physiological systems, such
        as lung tissue. Unlike volume, the fractal dimension of the tissue expands before the transition point as
        cancerous tissues have greater internal complexity. Therefore, assessing cancerous tissue using their fractal
        properties allows for earlier intervention.
      </p>

    </section>


    <section>
      <p>
        The colloquial phrase <em>How long is a piece of string</em> referring to an unknowable quantity can highlight
        some of the issues with reductionism. At each scale, more and more information is required to prop up previous
        arguments and knowledge. This regression continues ad infinitum, not only providing a foundational issue but
        also making accurate models of some scenarios unworkable in practice; the non-linearities compile into chaos. In
        light of the significant advances made through reductionism however, it would be naive to exclude it from any
        further research. There are inevitably metaphysical issues with any ontological theory; for example, a fractal
        foundation of mathematics would rely on circularity. In this essay I have argued that each perspective (be it
        reductionist, fractalist, et cetera) excels in specific areas and can be used in tandem. On the other hand, as
        reductionism has been the default method since the Scientific Revolution, many fields would benefit by switching
        to a new model of complexity that better matches their fundamental processes.
      </p>
    </section>
  </main>
</body>

</html>